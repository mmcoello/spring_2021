{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core scientific libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# secondary libraries\n",
    "import netCDF4 as nc\n",
    "from wrf import (to_np, getvar, smooth2d, get_cartopy, cartopy_xlim,\n",
    "                 cartopy_ylim, latlon_coords, interplevel, CoordPair, vertcross, g_uvmet, interpline, destagger,\n",
    "                interp2dxy, ll_to_xy, xy, ALL_TIMES, vinterp, uvmet)\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "import metpy.constants as constants\n",
    "from math import fabs, log, cos, sin, tan, pi\n",
    "\n",
    "import pytz\n",
    "\n",
    "from xarray.backends.netCDF4_ import NetCDF4DataStore\n",
    "\n",
    "import copy \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened File: ../input_data/wrfout_d03_2017-05-22_00:00:00 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set filepath\n",
    "datdir = '../input_data/'\n",
    "filename = 'wrfout_d03_2017-05-22_00:00:00'\n",
    "\n",
    "# set output filepath\n",
    "outdir = '/home/sbarc/students/coello/repos/classes/spring_2021/geog_288cj/post_processing/outputs/'\n",
    "fig_outdir = '/home/sbarc/students/coello/repos/classes/spring_2021/geog_288cj/post_processing/outputs/figures/'\n",
    "dat_outdir = '/home/sbarc/students/coello/repos/classes/spring_2021/geog_288cj/post_processing/outputs/data/'\n",
    "\n",
    "\n",
    "# open wrf Dataset object\n",
    "filepath = datdir + filename\n",
    "print('Opened File:', filepath, '\\n')\n",
    "\n",
    "# Open NetCDF Dataset object\n",
    "f = nc.Dataset(filepath,'r')\n",
    "\n",
    "# List variable names\n",
    "#print(\"Variables:\")\n",
    "#print(f.variables.keys(),'\\n')\n",
    "\n",
    "# Show variavles and all details\n",
    "#print(f.variables.items(),'\\n')\n",
    "\n",
    "# Show dimension names and sizes\n",
    "#print(\"Dimensions:\")\n",
    "#print(f.dimensions.items(),'\\n')\n",
    "\n",
    "# Print all file metadata\n",
    "#print(f)   # or run 'ncdump -h <filename>' in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Variable:T2\n",
      "Opened Variable:slp\n",
      "Opened Variable:uvmet10\n",
      "Opened Variable:uvmet10_wspd_wdir\n",
      "Opened Variable:rh2\n",
      "----------------------\n",
      "time: 19.1366126537323\n"
     ]
    }
   ],
   "source": [
    "# specify desired variables to grad from the wrf out file and their units\n",
    "des_vars = [\"T2\", \"slp\", \"uvmet10\", \"uvmet10_wspd_wdir\", \"rh2\"]\n",
    "var_units = [None, \"hpa\", \"m s-1\", \"m s-1\", None]\n",
    "\n",
    "# specify the z levels to interpolate to [km]\n",
    "v_levels = np.arange(0, 21, 0.05)\n",
    "\n",
    "# specify the time index desired\n",
    "indx = ALL_TIMES\n",
    "\n",
    "# make empty list to append interpolated dataarrays too\n",
    "data = []\n",
    "\n",
    "# start timer\n",
    "t0 = time.time()\n",
    "\n",
    "for i in range(len(des_vars)):\n",
    "    \n",
    "    # grab var with units at time index\n",
    "    if (var_units[i] != None):\n",
    "        tmp = getvar(f, des_vars[i], units = var_units[i], timeidx = indx)\n",
    "    else:\n",
    "        tmp = getvar(f, des_vars[i], timeidx = indx)\n",
    "    \n",
    "    # interpolate to z levels\n",
    "    if (des_vars[i] == \"uvmet10\" or des_vars[i] == \"uvmet10_wspd_wdir\"): # some get vars output two variables\n",
    "        tmp_1, tmp_2 = tmp\n",
    "        \n",
    "        if (des_vars[i] == \"uvmet10\"):\n",
    "            tmp_1 = tmp_1.rename('u').drop(\"u_v\")\n",
    "            tmp_2 = tmp_2.rename('v').drop(\"u_v\")\n",
    "        else:\n",
    "            tmp_1 = tmp_1.rename('wspd').drop(\"wspd_wdir\")\n",
    "            tmp_2 = tmp_2.rename('wdir').drop(\"wspd_wdir\")\n",
    "         \n",
    "        print(\"Opened Variable:\" + des_vars[i])\n",
    "\n",
    "        # fix projection labeling for saving as a netcdf https://github.com/NCAR/wrf-python/issues/91\n",
    "        del tmp_1.attrs['coordinates']\n",
    "        del tmp_2.attrs['coordinates']\n",
    "        \n",
    "        tmp_1.attrs['projection'] = str(tmp_1.attrs['projection'])\n",
    "        tmp_2.attrs['projection'] = str(tmp_2.attrs['projection'])\n",
    "\n",
    "        # append to list\n",
    "        data.append(tmp_1)\n",
    "        data.append(tmp_2)\n",
    "\n",
    "        \n",
    "    else:\n",
    "        print(\"Opened Variable:\" + des_vars[i])\n",
    "\n",
    "        # fix projection labeling for saving as a netcdf https://github.com/NCAR/wrf-python/issues/91\n",
    "        del tmp.attrs['coordinates']\n",
    "\n",
    "        tmp.attrs['projection'] = str(tmp.attrs['projection'])\n",
    "\n",
    "        # append to list\n",
    "        data.append(tmp)\n",
    "    \n",
    "    \n",
    "# merge into one dataset    \n",
    "data = xr.merge(data)\n",
    "\n",
    "# add terrian height to dataset after correcting the projection labeling\n",
    "terr = getvar(f, \"ter\", units = 'm', timeidx = 0)\n",
    "\n",
    "del terr.attrs['coordinates']\n",
    "\n",
    "terr.attrs['projection'] = str(terr.attrs['projection'])\n",
    " \n",
    "data['terr']  = terr  \n",
    "    \n",
    "# pull lat and lon vallues and replace current corrdinates\n",
    "lats = data.XLAT.values[:,0]\n",
    "lons = data.XLONG.values[0,:]\n",
    "\n",
    "data['south_north'] = lats\n",
    "data['west_east'] = lons\n",
    "\n",
    "# remane dimensions with ugly names\n",
    "data = data.rename({'south_north':'lat', 'west_east':'lon', 'XTIME':'time', 'XLAT':'lat_grid', \n",
    "                    'XLONG':'lon_grid'})\n",
    "\n",
    "# fix the time coordinates\n",
    "data['time'] = data['Time']\n",
    "data = data.drop(\"Time\")\n",
    "\n",
    "# end timer\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print('----------------------')\n",
    "print(\"time:\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert temp from K to c\n",
    "data['T2'] = data['T2'] - 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Files As: \n",
      " /home/sbarc/students/coello/repos/classes/spring_2021/geog_288cj/post_processing/outputs/data/wrfout_d03_2017-05-22_00:00:00_surf\n"
     ]
    }
   ],
   "source": [
    "filename_out = filename + \"_surf\"\n",
    "\n",
    "data.to_netcdf(path = dat_outdir + filename_out)\n",
    "\n",
    "print('Saved Files As: \\n', dat_outdir + filename_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (general)",
   "language": "python",
   "name": "general"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
